//! Token usage and model information types.

/// Model information from the assistant message.
#[derive(Debug, Clone)]
pub struct ModelInfo {
    model_id: ModelId,
}

impl ModelInfo {
    /// Creates a new `ModelInfo` from a model identifier string.
    ///
    /// Accepts any value that can be converted into a `String` (e.g., `&str`,
    /// `String`, `Cow<str>`).
    ///
    /// # Examples
    ///
    /// ```rust
    /// # use cclv::model::usage::ModelInfo;
    /// let model = ModelInfo::new("claude-opus-4-5-20251101");
    /// assert_eq!(model.id(), "claude-opus-4-5-20251101");
    /// assert_eq!(model.display_name(), "Opus");
    /// ```
    pub fn new(model_id: impl Into<String>) -> Self {
        Self {
            model_id: ModelId(model_id.into()),
        }
    }

    /// Returns the full model identifier string.
    ///
    /// This is the raw model ID as reported by the Claude API (e.g.,
    /// `"claude-opus-4-5-20251101"`).
    pub fn id(&self) -> &str {
        &self.model_id.0
    }

    /// Returns a human-readable short name for the model.
    ///
    /// Extracts the model family name from the full identifier:
    /// - "Opus" for models containing "opus"
    /// - "Sonnet" for models containing "sonnet"
    /// - "Haiku" for models containing "haiku"
    /// - Falls back to the full ID for unrecognized models
    ///
    /// # Examples
    ///
    /// ```rust
    /// # use cclv::model::usage::ModelInfo;
    /// assert_eq!(ModelInfo::new("claude-opus-4-5-20251101").display_name(), "Opus");
    /// assert_eq!(ModelInfo::new("claude-sonnet-4-5-20250929").display_name(), "Sonnet");
    /// assert_eq!(ModelInfo::new("claude-haiku-3-5-20241022").display_name(), "Haiku");
    /// assert_eq!(ModelInfo::new("gpt-4").display_name(), "gpt-4");
    /// ```
    pub fn display_name(&self) -> &str {
        let id = &self.model_id.0;
        if id.contains("opus") {
            "Opus"
        } else if id.contains("sonnet") {
            "Sonnet"
        } else if id.contains("haiku") {
            "Haiku"
        } else {
            id
        }
    }
}

#[derive(Debug, Clone)]
struct ModelId(String);

/// Token usage statistics from a single message.
///
/// Tracks all token categories reported by the Claude API. These values are used
/// to calculate total token consumption and cost estimation (see FR-015, FR-016, FR-017).
///
/// # Token Categories
///
/// Claude's API reports tokens across four categories:
///
/// - **Input tokens**: Tokens sent to the model (prompt, context, user messages)
/// - **Output tokens**: Tokens generated by the model (assistant responses)
/// - **Cache creation tokens**: Input tokens written to the prompt cache (first occurrence)
/// - **Cache read tokens**: Input tokens retrieved from the prompt cache (subsequent uses)
///
/// # Cost Calculation
///
/// Cost estimation requires multiplying each token category by its per-token price
/// (which varies by model). This type provides the raw counts; pricing logic lives
/// in the statistics module.
///
/// # Aggregation
///
/// `TokenUsage` implements `Add` for aggregating statistics across multiple messages
/// or entire sessions. Addition is component-wise (each field sums independently).
///
/// # Examples
///
/// ```rust
/// # use cclv::model::usage::TokenUsage;
/// let usage = TokenUsage {
///     input_tokens: 1000,
///     output_tokens: 500,
///     cache_creation_input_tokens: 200,
///     cache_read_input_tokens: 300,
/// };
///
/// // Total input includes all input categories
/// assert_eq!(usage.total_input(), 1500);
///
/// // Total tokens includes input + output
/// assert_eq!(usage.total(), 2000);
/// ```
#[derive(Debug, Clone, Copy, Default)]
pub struct TokenUsage {
    /// Tokens sent to the model as part of the prompt.
    ///
    /// This excludes cached tokens (see `cache_creation_input_tokens` and
    /// `cache_read_input_tokens`).
    pub input_tokens: u64,

    /// Tokens generated by the model in its response.
    pub output_tokens: u64,

    /// Input tokens written to the prompt cache.
    ///
    /// These tokens are billed at the cache creation rate (typically higher
    /// than standard input tokens). This occurs when prompt caching is enabled
    /// and new content is cached.
    pub cache_creation_input_tokens: u64,

    /// Input tokens retrieved from the prompt cache.
    ///
    /// These tokens are billed at the cache read rate (typically lower than
    /// standard input tokens). This occurs when prompt caching is enabled and
    /// cached content is reused.
    pub cache_read_input_tokens: u64,
}

impl TokenUsage {
    /// Returns the total input tokens across all categories.
    ///
    /// This sums `input_tokens`, `cache_creation_input_tokens`, and
    /// `cache_read_input_tokens`. Used for calculating total input cost
    /// (each category may have different per-token pricing).
    pub fn total_input(&self) -> u64 {
        self.input_tokens + self.cache_creation_input_tokens + self.cache_read_input_tokens
    }

    /// Returns the total tokens (input + output) for this usage record.
    ///
    /// This is the sum of all input categories plus output tokens.
    pub fn total(&self) -> u64 {
        self.total_input() + self.output_tokens
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_model_info_display_name_opus() {
        let model = ModelInfo::new("claude-opus-4-5-20251101");
        assert_eq!(model.display_name(), "Opus");
    }

    #[test]
    fn test_model_info_display_name_sonnet() {
        let model = ModelInfo::new("claude-sonnet-4-5-20250929");
        assert_eq!(model.display_name(), "Sonnet");
    }

    #[test]
    fn test_model_info_display_name_haiku() {
        let model = ModelInfo::new("claude-haiku-3-5-20241022");
        assert_eq!(model.display_name(), "Haiku");
    }

    #[test]
    fn test_model_info_display_name_unknown() {
        let model = ModelInfo::new("gpt-4");
        assert_eq!(model.display_name(), "gpt-4");
    }

    #[test]
    fn test_model_info_id_accessor() {
        let model = ModelInfo::new("claude-opus-4-5-20251101");
        assert_eq!(model.id(), "claude-opus-4-5-20251101");
    }

    #[test]
    fn test_token_usage_total_input() {
        let usage = TokenUsage {
            input_tokens: 100,
            output_tokens: 50,
            cache_creation_input_tokens: 20,
            cache_read_input_tokens: 30,
        };
        assert_eq!(usage.total_input(), 150);
    }

    #[test]
    fn test_token_usage_total() {
        let usage = TokenUsage {
            input_tokens: 100,
            output_tokens: 50,
            cache_creation_input_tokens: 20,
            cache_read_input_tokens: 30,
        };
        assert_eq!(usage.total(), 200);
    }

    #[test]
    fn test_token_usage_default() {
        let usage = TokenUsage::default();
        assert_eq!(usage.input_tokens, 0);
        assert_eq!(usage.output_tokens, 0);
        assert_eq!(usage.cache_creation_input_tokens, 0);
        assert_eq!(usage.cache_read_input_tokens, 0);
    }
}
